library(shiny); runApp('essai.R')
runApp('essai.R')
runApp('essai.R')
runApp('essai.R')
runApp('essai.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp()
shiny::runApp()
runApp()
runApp('main.R')
runApp()
runApp()
runApp('main.R')
runApp('main.R')
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(knitr)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
cache=TRUE, size="scriptsize",fig.width=6, fig.height=5)
library(reticulate)
#use_python("/Library/Frameworks/Python.framework/Versions/3.6/bin/python3", required = T)
knitr::knit_engines$set(python.reticulate =  TRUE)
#py_install("matplotlib")
py_install("scikit-learn")
#install.packages("rmarkdown")
library(magrittr)
library(knitr)
library(rmarkdown)
library(xlsx)
runApp()
runApp()
#install.packages("rmarkdown")
library(magrittr)
library(knitr)
library(rmarkdown)
library(ggplot2)
library(ggfortify)
#install.packages("rmarkdown")
library(magrittr)
library(knitr)
library(rmarkdown)
library(ggplot2)
library(MASS)
library(dplyr)
library(ISLR)
#install.packages("rmarkdown")
library(magrittr)
library(knitr)
library(rmarkdown)
library(ggplot2)
library(MASS)
library(dplyr)
library(readr)
#install.packages("rmarkdown")
library(magrittr)
library(knitr)
library(rmarkdown)
library(ggplot2)
library(MASS)
library(dplyr)
library(randomForest)
library(tidyverse)
#install.packages("rmarkdown")
library(magrittr)
library(knitr)
library(rmarkdown)
library(ggplot2)
library(MASS)
library(dplyr)
library(randomForest)
library(caret)
library(cluster)
library(factoextra)
id <- "1GNbIhjdhuwPOBr0Qz82JMkdjUVBuSoZd"
tennis <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download",id), header = T)
# test and train set
n = dim(tennis)[1]
n2 = n*(3/4)
set.seed(1234)
train = sample(c(1:n), replace = F)[1:n2]
# reduction to two variables
tennis$ACEdiff = tennis$ACE.1 - tennis$ACE.2
tennis$UFEdiff = tennis$UFE.1 - tennis$UFE.2
head(tennis)
names(tennis)
set.seed(71)
accuracyrate <- rep(NA,20)
deg = 1:20
for (d in deg) {
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=d)
model.confusion_matrix = model$confusion
model.accuracyrate = (model.confusion_matrix[1,1] + model.confusion_matrix[2,2]) / (model.confusion_matrix[1,1] + model.confusion_matrix[1,2] + model.confusion_matrix[2,1] +model.confusion_matrix[2,2])
accuracyrate[d] = model.accuracyrate
model.accuracyrate
}
id <- "1GNbIhjdhuwPOBr0Qz82JMkdjUVBuSoZd"
tennis <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download",id), header = T)
# test and train set
n = dim(tennis)[1]
n2 = n*(3/4)
set.seed(1234)
train = sample(c(1:n), replace = F)[1:n2]
# reduction to two variables
tennis$ACEdiff = tennis$ACE.1 - tennis$ACE.2
tennis$UFEdiff = tennis$UFE.1 - tennis$UFE.2
head(tennis)
names(tennis)
tennisTest = tennis[-train, ]
tennisTrain = tennis[train, ]
r.tennis2 = glm(Result ~ ACEdiff + UFEdiff, data = tennisTrain)
summary(r.tennis2)
set.seed(71)
accuracyrate <- rep(NA,20)
deg = 1:20
for (d in deg) {
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=d)
model.confusion_matrix = model$confusion
model.accuracyrate = (model.confusion_matrix[1,1] + model.confusion_matrix[2,2]) / (model.confusion_matrix[1,1] + model.confusion_matrix[1,2] + model.confusion_matrix[2,1] +model.confusion_matrix[2,2])
accuracyrate[d] = model.accuracyrate
model.accuracyrate
}
#The best model is
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
set.seed(71)
accuracyrate <- rep(NA,20)
deg = 1:20
for (d in deg) {
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=d)
model.confusion_matrix = model$confusion
model.accuracyrate = (model.confusion_matrix[1,1] + model.confusion_matrix[2,2]) / (model.confusion_matrix[1,1] + model.confusion_matrix[1,2] + model.confusion_matrix[2,1] +model.confusion_matrix[2,2])
accuracyrate[d] = model.accuracyrate
model.accuracyrate
}
#The best model is
model <-  randomForest(tennisTrain["Result"] ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
runApp()
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
runApp()
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
model <-  randomForest(df[['Result']]  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
model <-  randomForest(df['Result']  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- 'Result'
model <-  randomForest(df[,x]  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- 'Result'
df[,x]
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
df[,x]
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
tennisTrain[,x]
model <-  randomForest(df[,x]  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
tennisTrain[,x]
model <-  randomForest(tennisTrain[,x]  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
runApp()
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
tennisTrain[,x]
model <-  randomForest(tennisTrain[,x]  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
tennisTrain[,x]
model <-  randomForest(tennisTrain[,x]  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
tennisTrain[,x]
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model
runApp()
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
tennisTrain[,x]
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$forest
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
tennisTrain[,x]
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$forest
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
tennisTrain[,x]
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$predicted
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$predicted
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$confusion
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$confusion[,2]
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$confusion[:,2]
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$confusion[,2]
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$confusion[c(1,2),2]
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$confusion
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$confusion[1:2,1:2]
model$confusion
ui_model_result_error <- sidebarLayout(
sidebarPanel(),
mainPanel(
verbatimTextOutput("confusionmatrix")
)
)
runApp('main.R')
runApp()
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
summary(model)
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
anova(model)
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
anova(model)
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$err.rate
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
str(model)
runApp()
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
print(model)
ui_model_result <- mainPanel(
tabsetPanel(
tabPanel("Summary", ui_model_result_summary),
tabPanel("Prediction", ui_model_result_prediction),
tabPanel("Confusion Matrix and Error", ui_model_result_error)
))
runApp('main.R')
set.seed(71)
accuracyrate <- rep(NA,20)
#The best model is
x <- "Result"
model <-  randomForest(as.factor(tennisTrain[,x])  ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
model$votes
set.seed(71)
accuracyrate <- rep(NA,20)
deg = 1:20
for (d in deg) {
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=d)
model.confusion_matrix = model$confusion
model.accuracyrate = (model.confusion_matrix[1,1] + model.confusion_matrix[2,2]) / (model.confusion_matrix[1,1] + model.confusion_matrix[1,2] + model.confusion_matrix[2,1] +model.confusion_matrix[2,2])
accuracyrate[d] = model.accuracyrate
model.accuracyrate
}
p <- ggplot(deg, accuracyrate)
set.seed(71)
accuracyrate <- rep(NA,20)
deg = 1:20
for (d in deg) {
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=d)
model.confusion_matrix = model$confusion
model.accuracyrate = (model.confusion_matrix[1,1] + model.confusion_matrix[2,2]) / (model.confusion_matrix[1,1] + model.confusion_matrix[1,2] + model.confusion_matrix[2,1] +model.confusion_matrix[2,2])
accuracyrate[d] = model.accuracyrate
model.accuracyrate
}
p <- ggplot(deg, aes(accuracyrate))
set.seed(71)
accuracyrate <- rep(NA,20)
deg = 1:20
for (d in deg) {
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=d)
model.confusion_matrix = model$confusion
model.accuracyrate = (model.confusion_matrix[1,1] + model.confusion_matrix[2,2]) / (model.confusion_matrix[1,1] + model.confusion_matrix[1,2] + model.confusion_matrix[2,1] +model.confusion_matrix[2,2])
accuracyrate[d] = model.accuracyrate
model.accuracyrate
}
p <- ggplot() +geom_point(deg, aes(accuracyrate))
set.seed(71)
accuracyrate <- rep(NA,20)
deg = 1:20
for (d in deg) {
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=d)
model.confusion_matrix = model$confusion
model.accuracyrate = (model.confusion_matrix[1,1] + model.confusion_matrix[2,2]) / (model.confusion_matrix[1,1] + model.confusion_matrix[1,2] + model.confusion_matrix[2,1] +model.confusion_matrix[2,2])
accuracyrate[d] = model.accuracyrate
model.accuracyrate
}
p <- geom_line(deg, aes(accuracyrate))
set.seed(71)
accuracyrate <- rep(NA,20)
deg = 1:20
for (d in deg) {
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=d)
model.confusion_matrix = model$confusion
model.accuracyrate = (model.confusion_matrix[1,1] + model.confusion_matrix[2,2]) / (model.confusion_matrix[1,1] + model.confusion_matrix[1,2] + model.confusion_matrix[2,1] +model.confusion_matrix[2,2])
accuracyrate[d] = model.accuracyrate
model.accuracyrate
}
p <- ggplot(aes(deg)) + geom_line(aes(y = accuracyrate, colour = "Actual"))
set.seed(71)
accuracyrate <- rep(NA,20)
deg = 1:20
for (d in deg) {
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=d)
model.confusion_matrix = model$confusion
model.accuracyrate = (model.confusion_matrix[1,1] + model.confusion_matrix[2,2]) / (model.confusion_matrix[1,1] + model.confusion_matrix[1,2] + model.confusion_matrix[2,1] +model.confusion_matrix[2,2])
accuracyrate[d] = model.accuracyrate
model.accuracyrate
}
p <- plot(deg, accuracyrate, type = "l", lty = 1)
print(p)
#The best model is
model <-  randomForest(as.factor(Result) ~ ACEdiff + UFEdiff, data=tennisTrain,
mtry = 2, ntree = 500, nodesize=which.max(accuracyrate))
runApp('main.R')
runApp('main.R')
runApp()
runApp()
useShinyjs(),
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
install.packages("shinyjs")
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
runApp('main.R')
library(shiny); runApp('main.R')
runApp()
runApp()
runApp()
runApp()
runApp('main.R')
runApp()
